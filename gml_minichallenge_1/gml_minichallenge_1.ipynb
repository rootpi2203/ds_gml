{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27574a18ec8ec4434b84830de7f4eea6",
     "grade": false,
     "grade_id": "cell-a14a0e42fb32bf6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# GML - Mini-Challenge 1 - FS 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dff6a9df2010d8480d9e53fdb73bd23d",
     "grade": false,
     "grade_id": "cell-c39ca46dd5223598",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Ausgabe:** Montag, 21. März 2022  \n",
    "**Abgabe:** Sonntag, 24. April 2022, bis 24 Uhr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e67532a9c3c9752ece899065baca52f6",
     "grade": false,
     "grade_id": "cell-c101d4d4ed7daa5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In dieser Mini-Challenge implementieren und verwenden wir verschiedene Supervised Learning-Methoden und machen Gebrauch von Model Selection-Prinzipien und -Algorithmen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "626f32cc5a7e6b277b2d79f23e86ae1f",
     "grade": false,
     "grade_id": "cell-537cbbbfba1472ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Vorgaben zu Umsetzung und Abgabe\n",
    "\n",
    "- Code muss in python geschrieben werden.\n",
    "- Wir entwickeln zahlreiche Algorithmen selber. Wenn nicht explizit anders verlangt, dürfen bloss die folgenden Bibliotheken verwendet werden: numpy, matplotlib, seaborn, pandas\n",
    "- Der Code muss von Anfang bis Ende lauffähig sein bei Ausführung im Docker-Container des Trainingcenters. Nur was korrekt ausführt wird bewertet.\n",
    "- Es darf kein Code ausgelagert werden.\n",
    "- Sämtliche Plots sind komplett beschriftet (Achsen, Labels, Titel, Colorbar, ..), sodass der Plot einfach verstanden werden kann.\n",
    "- Zu jedem Plot gehört eine kurze Diskussion, welche den Plot erklärt und die wichtigsten Einsichten die damit sichtbar werden festhält.  \n",
    "- Als **Abgabe** zählt der letzte Commit in deinem Fork des Repos vor Abgabetermin.  \n",
    "\n",
    "\n",
    "- **Bitte lösche, dupliziere oder verschiebe die vorhandenen Zellen nicht**. Dies führt zu Problemen bei der Korrektur. Du darfst aber beliebig viele weitere Zellen hinzufügen.\n",
    "- Bitte importiere Daten mit **relativen Pfaden** innerhalb des Repos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2831ec2cdf1c8dc267c5b2557e6715a9",
     "grade": false,
     "grade_id": "cell-a30ee27b9dd26d68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Für die Erarbeitung der Lösung darf unter Studierenden zusammengearbeitet werden. Die Zusammenarbeit ist dabei aber auf konzeptionelle und algorithmische Fragen und Verständnisaspekte beschränkt.  \n",
    "\n",
    "**Es darf kein Code oder Text von anderen oder vom Internet kopiert werden.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c0315ee98213c54058c1b1fbdf5681d",
     "grade": false,
     "grade_id": "cell-444e8bb1dde427ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8e7f6972ace9fae35b9e943ba27612e",
     "grade": false,
     "grade_id": "cell-598892315ccef79b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 1 (4 Punkte)\n",
    "\n",
    "**Ridge Regression** (siehe beispielsweise James et al., *An Introduction to Statistical Learning*, 2015, pp 215) ist eine regularisierte Form ($l_2$-Regularisierung) der Ordinary Least Squares (OLS) Kostenfunktion für die lineare Regression.  \n",
    "\n",
    "Die Ridge Regression-Kostenfunktion für einen Datensatz $(x^{(i)}, y^{(i)})$ mit $x^{(i)} = (x_1^{(i)}, \\dots , x_p^{(i)})$ von $N$ Datenpunkten ist: \n",
    "\n",
    "\\begin{equation}\n",
    "J(\\beta) = \\sum_{i=1}^{N} (y^{(i)}-\\beta_0 - \\sum_{j=1}^{p} x^{(i)}_j\\beta_j)^2 + \\alpha\\sum_{j=1}^{p} \\beta_j^2 \n",
    "\\end{equation}\n",
    "\n",
    "$(\\beta_0, \\beta_1, \\dots, \\beta_p)$ sind dabei die Modellkoeffizienten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7540cd5b9649999e5b06e384583d2af",
     "grade": false,
     "grade_id": "cell-50f0d41613015609",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Es gilt zu beachten, dass bei Ridge Regression der Achsenabschnitt, i.e. der Modellkoeffizient $\\beta_0$ nicht in den Penalty Term der Kostenfunktion eingeht. Das zeigt sich in obiger Gleichung durch die Summe von $i=1$ (nicht $i=0$) bis $p$ (Anzahl Prädiktoren)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "442ebc941f9820d89108fbbaaf900150",
     "grade": false,
     "grade_id": "cell-d1a4ded98458d714",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Für die Optimierung der Koeffizienten bei gegebenem Datensatz ergeben sich dadurch Implikationen für Gradient Descent und Normalengleichung.  \n",
    "\n",
    "Wenn man die Input-Variablen standardisiert, was **bei Regularisierung fast immer angezeigt** ist um sämtliche Variablen auf eine vergleichbare Skala (dimensionslose Standardabweichungen) zu bringen, und damit die zugehörigen Koeffizienten in ähnlichem Umfang zu regularisieren, ist es eine Möglichkeit das Optimierungsproblem für $\\beta_0$ und die restlichen Variablen zu separieren. $\\beta_0$ kann dann nämlich mit $\\beta_0 = \\frac{1}{N} \\sum_{i=1}^{N}y^{(i)}$ berechnet werden und ist so unregularisiert. Die Koeffizienten $(\\beta_1, \\dots, \\beta_p)$ werden dann mit Gradient Descent oder Normalengleichen optimiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a309647b35b0ed51ceebb994b2fdf10",
     "grade": false,
     "grade_id": "cell-969ac96f1888af28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Möchte man alle Modell-Koeffizienten, inklusive $\\beta_0$, mittels Gradient Descent optimieren, so gilt es eine Fallunterscheidung bei der Berechnung des Gradienten zu machen für die Gradienten-Komponente $0$, welche zum Koeffizienten $\\beta_0$ gehört, und den verbleibenden Gradienten-Komponenten $1$ bis $p$, welche zu den Modellkoeffizienten $(\\beta_1, \\dots, \\beta_p)$ gehören. Dies deswegen, weil $\\beta_0$ nicht in die Strafterm-Summe der Kostenfunktion eingeht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57cf692fe1e428bba285f773b8e29711",
     "grade": false,
     "grade_id": "cell-56f0ecde3f599460",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Zu Gradient Descent für Ridge Regression\n",
    "\n",
    "Zur Verwendung von Gradient Descent muss der Gradient der Kostenfunktion berechnet werden. Der Gradient $\\nabla f(\\chi)$ einer Funktion $f(\\cdot)$ mehrerer ($m$) Variablen $\\chi = (\\chi_1, \\chi_2, \\dots, \\chi_m)$ ist gegeben durch:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla f(\\chi) = \\Big( \\frac{\\partial f(\\chi)}{\\partial \\chi_1}, \\frac{\\partial f(\\chi)}{\\partial \\chi_2}, \\dots, \\frac{\\partial f(\\chi)}{\\partial \\chi_m}\\Big)\n",
    "\\end{equation}\n",
    "\n",
    "$\\frac{\\partial f(\\chi)}{\\partial \\chi_i}$ ist dabei die partielle Ableitung von $f(\\cdot)$ nach $\\chi_i$. $\\nabla f(\\chi)$ ist also ein $m$-dimensionaler Vektor.   \n",
    "\n",
    "Bei Standardisierung der Input-Variablen und separater 'Optimierung' von $\\beta_0$ wird $\\beta_0$ vorab berechnet, wird dann zur Konstanten in der Kostenfunktion, und muss nicht mehr mitoptimiert werden, i.e. kann beim Gradienten aussen vor gelassen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f474a567191595bd7520380c2b82ff89",
     "grade": false,
     "grade_id": "cell-e9c12302c2d018bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Zur Normalengleichung für Ridge Regression\n",
    "\n",
    "Einen Input-Datensatz können wir als $N \\times p+1$ Matrix $\\mathbf{X}$ schreiben. $p+1$ deswegen, weil wir den $p$ Input-Variablen noch eine Spalte von $1$-en voranstellen können, um den Koeffizienten $\\beta_0$ mit berücksichtigen zu können. Sie hat also die Form\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X} = \n",
    "\\begin{bmatrix}\n",
    "1 & x^{(1)}_1 & x^{(1)}_2 & \\cdots & x^{(1)}_j & \\cdots & x^{(1)}_p \\\\\n",
    "1 & x^{(2)}_1 & x^{(2)}_2 & \\cdots & x^{(2)}_j & \\cdots & x^{(2)}_p \\\\\n",
    "& & \\vdots & &\\\\\n",
    "1 & x^{(i)}_1 & x^{(i)}_2 & \\cdots & x^{(i)}_j & \\cdots & x^{(i)}_p \\\\\n",
    "& & \\vdots & &\\\\\n",
    "1 & x^{(n)}_1 & x^{(n)}_2 & \\cdots & x^{(n)}_j & \\cdots & x^{(n)}_p\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Gleichermassen können wir unsere Output-Variablen als $N$-dimensionalen Vektor $y = (y^{(1)}, .. y^{(N)})$ betrachten.  \n",
    "\n",
    "Damit können wir ein lineares Modell in kompakter Schreibweise wie folgt formulieren:  \n",
    "\n",
    "\\begin{equation}\n",
    "y = \\mathbf{X}\\beta + \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "Wobei $\\epsilon = (\\epsilon_1, \\cdots \\epsilon_N)$ ein Vektor von irreduzierbaren Fehlern für die $N$ Datenpunkte ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9703d4d051aa85305fd5445668a8b73",
     "grade": false,
     "grade_id": "cell-2005988b23517f35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Für die **unregularisierte OLS Kostenfunktion kann eine analytische Lösung** gefunden werden, die als Normalengleichung bezeichnet wird:\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^Ty\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Gleichermassen kann für die analytische Lösung der **Ridge Regression Kostenfunktion** folgende analytische Lösung hergeleitet werden:\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta = (\\mathbf{X}^T \\mathbf{X} + \\alpha \\mathbf{1}_R)^{-1} \\mathbf{X}^Ty\n",
    "\\end{equation}\n",
    "\n",
    "Möchten wir alle Modellkoeffizienten, inklusive $\\beta_0$, auf einmal optimieren, ist $\\mathbf{1}_R$ dabei im Grunde die $(p+1 \\times p+1)$-dimensionale Einheitsmatrix. Allerdings muss das Element $(0,0)$ gleich $0$ gesetzt, dies um den Koeffizienten $\\beta_0$ nicht zu regularisieren. $\\mathbf{1}_R$ ist also:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{1}_r = \n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & \\cdots & 0 & \\cdots & 0 \\\\\n",
    "0 & 1 & 0 & \\cdots & 0 & \\cdots & 0 \\\\\n",
    "0 & 0 & 1 & \\cdots & 0 & \\cdots & 0 \\\\\n",
    "& &  & \\ddots &  & \\vdots &  \\\\\n",
    "& \\vdots &  &  & \\ddots & 0 & 0 \\\\\n",
    "0 & 0 & \\cdots &  & 0 & 1 & 0 \\\\\n",
    "0 & 0 & \\cdots &  &  & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84ec1863eed2091a3b8261026a317879",
     "grade": false,
     "grade_id": "cell-e6a760b2b23174b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Bei standardisierten Inputdaten** kann alternativ auch der oben erwähnte Weg beschritten werden, bei welchem man $\\beta_0 = \\frac{1}{N} \\sum_{i=1}^{N}y^{(i)}$ berechnet, die Spalte von $1$-en $\\mathbf{X}$ nicht vorangestellt und schliesslich eine Normalengleichung verwendet wird mit unveränderter $(p \\times p)$-dimensionaler Einheitsmatrix $\\mathbf{1}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta = (\\mathbf{X}^T \\mathbf{X} + \\alpha \\mathbf{1})^{-1} \\mathbf{X}^Ty\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1bfef6aa079c89f70288de03e1908cb",
     "grade": false,
     "grade_id": "cell-9516abc3094115db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Du bist frei in diesem Aufgabenblatt einen beliebigen (korrekten) Weg für Gradient Descent und Normalengleichung zu wählen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc72356e2de44b78f7dfa6573f633b6a",
     "grade": false,
     "grade_id": "cell-7bea1f60917ace51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61d236d1da3db1f11236f8fb8996d68b",
     "grade": false,
     "grade_id": "cell-10d8b9e25ab34dee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Aufgabe**\n",
    "\n",
    "Leite für die obige Ridge Regression-Kostenfunktion den Gradienten und die Normalengleichung analytisch her, für den Fall dass die Inputdaten nicht standardisiert seien.  \n",
    "\n",
    "(Schreibe die Herleitung in LaTex-Notation in die folgende Zelle).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "483340bcb4559a70b175c329bff5928d",
     "grade": true,
     "grade_id": "cell-17b4f6f2b395d4a6",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "392fe1fa7c8c3a6a460351b77168014f",
     "grade": false,
     "grade_id": "cell-08d0ecc44ae0095f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 2 (3 Punkte)  \n",
    "\n",
    "Was würde sich in Aufgabe 1 ändern wenn wir anstelle von Ridge Regression Lasso betrachten würden für Kostenfunktion, Koeffizientenoptimierung und Koeffizienten?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b331ef5e94fb0ec53b3aef2bec763ad4",
     "grade": true,
     "grade_id": "cell-cc76f77b20062218",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a10c3a4bd82a722085d8867d84333c67",
     "grade": false,
     "grade_id": "cell-bf24b44d2be058ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 3 (8 Punkte)\n",
    "\n",
    "Komplettiere die folgende Klasse so, dass sie bei Wahl der entsprechenden Initialisierungsoption, das Ausführen der `fit`-Methode die Kostenfunktion der Ridge Regression-Kostenfunktion mit Gradient Descent (`gd`) oder der regularisierten Normalengleichung (`neq`) optimiert.\n",
    "\n",
    "Erstelle nun einen einfachen Datensatz von 1000 Datenpunkten zur Validierung deiner Implementation: Die eindimensionalen x-Werte seien normalverteilt mit Mittelwert 5 und Standardabweichung 3. Die y-Werte seien gegeben durch ein einfaches lineares Modell mit Koeffizienten $\\beta_0=-2$ und $\\beta_1=3$.\n",
    "\n",
    "Zeige damit, dass\n",
    "- deine Implementierung für Gradient Descent erfolgreich konvergiert.\n",
    "- du mit Normalengleichung und Gradient Descent praktisch die gleiche (korrekte) Lösung findest (verwende dazu `np.testing.assert_array_almost_equal`).\n",
    "- der Effekt der Regularisierung sich wie erwartet niederschlägt, wenn du die Werte für die Koeffizienten als Funktion er Regularisierungsstärke $\\alpha$ über den gesamten sinnvollen Bereich für $\\alpha$ zeichnest (Ridge Regression Path). Diskutieren diesen Plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67e96cbf073d00ed0ae2a560b60e370b",
     "grade": true,
     "grade_id": "cell-e3ecd12d03420258",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class RidgeRegression(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, opt_method='gd', alpha=1., eta=0.01, maxsteps=100, eps=0.00000001):\n",
    "        '''Implements a Ridge Regression estimator.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        alpha:      Regularization proportionality factor. Larger values\n",
    "                    correspond with stronger regularization.\n",
    "        opt_method: Optimization method to choose for the cost function.\n",
    "                    Can be either 'gd' (Gradient Descent) or 'neq'.\n",
    "        maxsteps:   Maximum number of Gradient Descent steps to take.\n",
    "        eps:        Epsilon, length of gradient to be reached with Gradient\n",
    "                    Descent.\n",
    "        eta:        Fixed step lenght to take at each gradient descent\n",
    "                    iteration.\n",
    "        '''\n",
    "        # parameters\n",
    "        self.alpha = alpha\n",
    "        self.opt_method = opt_method\n",
    "        self.maxsteps = maxsteps\n",
    "        self.eps = eps\n",
    "        self.eta = eta\n",
    "        # attributes\n",
    "        # model coefficients\n",
    "        self.beta_ = None\n",
    "        # values of cost function along gradient descent iterations\n",
    "        self.costs_ = []       \n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        '''\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return self\n",
    "        \n",
    "    def gradient_descent(self,X,y):\n",
    "        '''Computes the coefficients of the ridge regression cost function\n",
    "        using gradient descent.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def normalequation(self,X,y):\n",
    "        '''Computes the coefficients of the ridge regression cost function\n",
    "        using the normalequation.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @staticmethod\n",
    "    def gradient(beta,X,y,alpha):\n",
    "        '''Computes and returns the gradient of the ridge regression cost function.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @staticmethod \n",
    "    def costfunction(beta,X,y,alpha):\n",
    "        '''Computes and returns the value of the ridge regression cost function.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    \n",
    "    def predict(self,X):\n",
    "        '''Computes the predictions of the current model.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    \n",
    "    def score(self,X,y):\n",
    "        '''Returns R^2 for given input/output data given the model\n",
    "        coefficients.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def approximate_gradient(beta,X,y,alpha,epsilon=0.00001):\n",
    "        '''Approximates the gradient with finite differences.\n",
    "        \n",
    "        You can use this method to check your gradident.\n",
    "        '''\n",
    "        grad_approx = []\n",
    "        cf = RidgeRegression.costfunction\n",
    "        for i,b in enumerate(beta):\n",
    "            eps = np.zeros(beta.shape[0])\n",
    "            eps[i] += epsilon\n",
    "            print(eps)\n",
    "            grad_approx.append(\n",
    "                (cf(beta+eps,X,y,alpha)-cf(beta-eps,X,y,alpha))/(2*epsilon)\n",
    "            )\n",
    "        return np.array(grad_approx)\n",
    "    \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81d4b425313979972e8e5df27236818a",
     "grade": true,
     "grade_id": "cell-6d8e46bcf1165170",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "947ac3ace2228d3760ed06421017b046",
     "grade": false,
     "grade_id": "cell-9d564ff80880ce49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 4 (7 Punkte)\n",
    "\n",
    "Schreibe nun eine Funktion, die einen Contour Plot der Kostenfunktion erstellt (siehe dazu gml Aufgabenblatt 1 im Trainingcenter). Zeichne den Pfad von Gradient Descent durch die Koeffizientenebene ein (dazu musst du die obige Klasse modifizieren) und untersuche und vergleiche den Plot für\n",
    "\n",
    "- unterschiedliche Regularisierungsstärken, inkl. ohne Regularisierung.\n",
    "- mit und ohne Standardisierung der Input-Daten.\n",
    "\n",
    "Diskutiere deine Einsichten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bfe62747dc423cc699111b51416f112",
     "grade": true,
     "grade_id": "cell-072994ddc01c2295",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d81c379bcd42feca014b58c3e55a476",
     "grade": true,
     "grade_id": "cell-86ed5cdc25c06a1b",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa96bc51bfa2f016eb72be682d745c7e",
     "grade": false,
     "grade_id": "cell-a776cc30034b6f2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 5 (4 Punkte)\n",
    "\n",
    "Lade den Datensatz `data/moto.csv` und verschaffe dir einen Überblick durch explorative Datenanalyse. Unser Ziel wird es sein, den Preis (`price`) der Motorräder vorherzusagen unter Verwendung der übrigen Attribute. Teile deine Überlegungen zu diesem Problem.  \n",
    "\n",
    "Unterteile den Datensatz nun noch in Trainings- und Testdaten (80:20) für die weiteren Aufgaben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c774d9ebfb9cc1b2ef0c7c41aad6f23b",
     "grade": true,
     "grade_id": "cell-6bad7cb791f2cb0c",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af4bbd9d82cef4597f7fa6d7957980bc",
     "grade": true,
     "grade_id": "cell-aa4e32d1f9acea9a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d4d8e3c8e1e7025a8b615a5b871c784",
     "grade": false,
     "grade_id": "cell-028c6bce8cafd826",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 6 (3 Punkte)\n",
    "\n",
    "Erstelle ein erstes einfaches lineares Modell für `price`, bloss mit der einen Input-Variablen `displacement`.  \n",
    "\n",
    "Untersuche für die unregularisierte OLS-Lösung die Modell-Annahmen eines linearen Modells. Schau dir dazu *Kapitel 4 - Residuenanalyse* im Skript von Werner Stahel an, wenn du Anleitung möchtest.    \n",
    "\n",
    "Nimm, falls sinnvoll, Variablen-Transformationen vor, um dein Modell zu verbessern und untersuche den Effekt. Erkläre dein Vorgehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0aca2020fef5382360ab52da7ccd440c",
     "grade": true,
     "grade_id": "cell-1175683b3e469f07",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "502189a5f60da4508329fcc9de0d9e0c",
     "grade": true,
     "grade_id": "cell-7c65d0cdad8c19d1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5416f1a4f1c1069ce7b7e768eb7368b",
     "grade": false,
     "grade_id": "cell-4676bcfe39c11a07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 7 (4 Punkte)\n",
    "\n",
    "Entwickle nun dein bestes Ridge-Regression-Modell im Sinne von $R^2$ auf dem Trainingsdatensatz. Du darfst durch Feature-Transformation beliebige weitere Attribute hinzufügen. Gebe $R^2$ und MAE auf dem Testdatensatz an.\n",
    "\n",
    "Zur Optimierung der Hyperparameter kannst du scikit-learn-Funktionalität verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3600764a10f6f837ae5384df5857b2f9",
     "grade": true,
     "grade_id": "cell-c8b2568f340bda1a",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec7af4bd23f868ab39375b2654f983ae",
     "grade": true,
     "grade_id": "cell-dae4f34d368fcdeb",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c48b7faf9e4ff712ee0f8b34df3a1909",
     "grade": false,
     "grade_id": "cell-f039db7c5f629d17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 8 (4 Punkte)\n",
    "\n",
    "Erstelle einen Plot bei welchem du auf der x-Achse die Regularisierungsstärke $\\alpha$ und auf der y-Achse $R^2$ für Trainings- und Testdaten (zwei Kurven) zeichnest. Diskutiere den Plot hinsichtlich Bias-Variance Trade-Off und der Verallgemeinerungsfähigkeit des Modells.  \n",
    "\n",
    "Was ziehst du daraus für Schlüsse für weitere Modellierungsschritte?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdd2511cc68f17a6d93dad95f9140534",
     "grade": true,
     "grade_id": "cell-3c7f182708f86c2a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d14f655c895df26e63139c013216c54",
     "grade": true,
     "grade_id": "cell-19c5f45de63f73c9",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3782c2247e947870863bd49395f6a8f",
     "grade": false,
     "grade_id": "cell-76d35d0e51f7a3ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 9 (10 Punkte)\n",
    "\n",
    "Was ist das beste Modell für die Output-Variable `price` im Sinne von $R^2$, das du ohne Einschränkungen finden kannst?\n",
    "\n",
    "Vergleiche dazu mindestens drei weitere Ansätze miteinander.\n",
    "\n",
    "Wie verändert sich die Situation wenn du für den *Mean Absolute Error* (MAE) optimierst?\n",
    "\n",
    "Hierzu kannst du scikit-learn Funktionalität verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dafc6ca9eec22c9e7840df949f6180e3",
     "grade": true,
     "grade_id": "cell-76d9178f80e91550",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "557b204ea14ff8ce0fb40fa3dc0b8d1a",
     "grade": true,
     "grade_id": "cell-f49d6edea9f585c9",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02e93b46e9f8e5a2eb4bb89de79d2bbb",
     "grade": false,
     "grade_id": "cell-deb1a332cd0f2c86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 10 (4 Punkte)\n",
    "\n",
    "Stelle nun die Resultate der bisherigen Aufgaben und Modelle tabellarisch und graphisch übersichtlich dar und diskutiere sie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f3dfc525169dec929a7e0e67c72b9b1",
     "grade": true,
     "grade_id": "cell-fc430cac16df0d88",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf40ff2cf8567935ebffe998ca4b4db3",
     "grade": true,
     "grade_id": "cell-90051cdc8eaa5d18",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3e906472eee2f6993bee2fee4e52df9",
     "grade": false,
     "grade_id": "cell-e36873df0c0262e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 11 (8 Punkte)\n",
    "\n",
    "Nun betrachten wir noch dein bestes Modell etwas vertieft. Trainiere diesen Modell-Ansatz auf jeweils $[\\frac{1}{10}, \\frac{2}{10}, \\frac{3}{10}, .., \\frac{10}{10}]$ der Trainingsdaten. Erstelle nun einen Plot bei welchem der Wert der Kostenfunktion für die Trainings- und Testdaten auf der y-Achse und der Trainingsdatenanteil auf der x-Achse liegen möge. Zeichne also zwei Kurven in dieses Koordinatensystem.\n",
    "\n",
    "Schau dir dazu das Video von [Kilian Weinberger zu Model Selection](https://www.youtube.com/watch?v=a7cofmFgwIk&list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS&index=22) an.  \n",
    "\n",
    "Interpretiere und diskutiere nun deine Einsichten zu Model Selection, Bias & Variance und Grösse des Datensatzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48f8a2cbb4285cf7423a6afcf418b578",
     "grade": true,
     "grade_id": "cell-b5a7adbdf7bdd16c",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e62f43ee707f43f2ad20b107985f0f5a",
     "grade": true,
     "grade_id": "cell-f51cd5301642eb12",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
