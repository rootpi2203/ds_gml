{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75efbebc75204457808c12958f9f80d3",
     "grade": false,
     "grade_id": "cell-01169bd0ece66b59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# GML - Mini-Challenge 2 - FS 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a6313a3bd0b720de2ef428bd1749d06",
     "grade": false,
     "grade_id": "cell-51511e92ebb43b81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Ausgabe:** Montag, 25. April 2022  \n",
    "**Abgabe:** Sonntag, 22. Mai 2022, bis 24 Uhr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3dcc9c4d732c4937cee1b14d3e9f948",
     "grade": false,
     "grade_id": "cell-8807c7bd8547b484",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In diesem Mini-Challenge implementieren und verwenden wir verschiedene Methoden der Klassifikation, machen Gebrauch von Model Selection-Prinzipien und -Algorithmen und stellen Gedanken zu Ensemble Methoden an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8526f989fc03610d22b2814db69b0de",
     "grade": false,
     "grade_id": "cell-73fd25a75a328fa0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Vorgaben zu Umsetzung und Abgabe\n",
    "\n",
    "- Code muss in python geschrieben werden.\n",
    "- Wir entwickeln die meisten Algorithmen selber. Wenn nicht explizit anders verlangt, dürfen bloss die folgenden Bibliotheken verwendet werden: numpy, matplotlib, seaborn, pandas\n",
    "- Der Code muss lauffähig sein bei Ausführung im Docker-Container des Trainingcenters. \n",
    "- Es darf kein Code ausgelagert werden.\n",
    "- Sämtliche Plots sind komplett beschriftet (Achsen, Labels, Colorbar, ..) um den Plot verstehen zu können.\n",
    "- Zu jedem Plot gibt es eine kurze Diskussion, welche den Plot erklärt und die wichtigsten Einsichten die damit sichtbar werden festhält.  \n",
    "- Als **Abgabe** zählt der letzte Commit in deinem Fork des Trainingcenter Repos vor Abgabetermin.  \n",
    "\n",
    "\n",
    "\n",
    "- **Bitte lösche, dupliziere oder verschiebe die vorhandenen Zellen nicht**. Dies führt zu Problemen bei der Korrektur. Du darfst aber beliebig viele weitere Zellen hinzufügen.\n",
    "- Bitte importiere Daten mit **relativen Pfaden** innerhalb des Repos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4bf210d6f414fceff9c9f49a629c5a5",
     "grade": false,
     "grade_id": "cell-f2faac4ed5164e65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Für die Erarbeitung der Inhalte darf unter Studierenden zusammengearbeitet werden. Die Zusammenarbeit ist dabei aber auf algorithmische Fragen und Verständnisaspekte beschränkt.  \n",
    "\n",
    "**Es darf kein Code oder Text von anderen oder vom Internet kopiert werden.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d438166a2d6ceec273ff24b1e967883b",
     "grade": false,
     "grade_id": "cell-1e2dfa6fbb4946e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83d1b007bd90fd3ee834d0b56fcd2da2",
     "grade": false,
     "grade_id": "cell-50d70fae1e6fa2a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 1 - EDA (4 Punkte)\n",
    "\n",
    "Lade den Datensatz `data/moto.csv` und verschaffe dir einen Überblick durch explorative Datenanalyse. Unser Ziel wird es sein, die Marke der Motorräder vorherzusagen unter Verwendung der übrigen Attribute. Teile deine Überlegungen zu diesem Problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e3b15a6a9f663280affebe5ff1792c3",
     "grade": true,
     "grade_id": "cell-c8fa1865bdef2295",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e60ce2e5ab67927dd420accf1f5088e",
     "grade": true,
     "grade_id": "cell-da020b66b3b5e2fb",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1d0b561e41244ee103a1106a281d581",
     "grade": false,
     "grade_id": "cell-8512d784051efce1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 2 - Testing / Metrics (4 Punkte)\n",
    "\n",
    "Unterteile den Datensatz sinnvoll in Trainings- und Testteil. Wir werden von diesen Teilen in sämtlichen kommenden Aufgaben Gebrauch machen.\n",
    "\n",
    "Als Zielmetrik werden wir über alle kommenden Aufgaben mit dem mittleren F1-Score arbeiten, individuell berechnet über alle Klassen.  \n",
    "Erörtere, was die Eigenschaften dieser Metrik sind und wann sie sinnvoll ist, wann nicht. Trifft dies hier zu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a21c205e6b8aa49426024f22b262be38",
     "grade": true,
     "grade_id": "cell-a035d5ff815a1dbc",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f84862e7b7c2c5131ee87bebae10e81d",
     "grade": true,
     "grade_id": "cell-7cb6704a4ca4d76f",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3d8190d0939badf568428c2c4b693af",
     "grade": false,
     "grade_id": "cell-c0cc720888f1bd89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 3 - Logistic Regression (5 Punkte)\n",
    "\n",
    "Als 'Baseline'-Modell verwenden wir logistische Regression.  \n",
    "\n",
    "Setze einen einfachen regularisierten, rein linearen logistischen Regressionsansatz um. Verwende dazu scikit-learn.  \n",
    "\n",
    "Evaluiere und diskutiere das Modell auf dem Testdatensatz. Zeichne die Confusion Matrix und berechne die Zielmetrik. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c50dae5b1bc217ea8dc4831c0ba7fb1",
     "grade": true,
     "grade_id": "cell-7ed3fc9d22e6f4e4",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e348b4093693504cd12e2f2981faa542",
     "grade": true,
     "grade_id": "cell-77b092169c230855",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e2fa58f2b09b23012e6dcf842ea9db8",
     "grade": false,
     "grade_id": "cell-629ad12369cad4fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 4 - Multi-Layer Perceptron (15 Punkte)\n",
    "\n",
    "Implementiere ein Multi-Layer Perceptron mit sigmoider Aktivierungsfunktion und $l_2$-Regularisierung durch Ergänzen der folgenden Klasse.  \n",
    "\n",
    "Zeige mit Hilfe des kleinen Entwicklungsdatensatzes `dev_data.csv`, dass die Umsetzung des Gradienten korrekt ist unter Verwendung der Methode `grad_check()`. \n",
    "Erkläre, was `grad_check` macht.\n",
    "\n",
    "Zeige weiter, dass\n",
    "\n",
    "- Gradient Descent konvergiert.\n",
    "- eine Accuracy > 0.8 erzielt werden kann.\n",
    "- die Regularisierung den gewünschten Effekt hat.\n",
    "\n",
    "Verwende aus der Library `mlxtend.plotting` die Funktion `plot_decision_regions` zum Zeichnen der Decision Regions und der Decision Boundary.  \n",
    "Bechreibe den Plot.  \n",
    "\n",
    "Ermögliche weiter die Verwendung der Bibliotheksfunktion `scipy.optimize.minimize` zur Optimierung der Modell-Koeffizenten $\\theta$.  \n",
    "Zeige, dass auch das funktioniert. Zeichne insbesondere den Verlauf der Kostenfunktion über das Iterationsverfahren hinweg, wenn du den Solver `L-BFGS-B` verwendest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2666d34f20a277e601dad5cbc1f10b45",
     "grade": true,
     "grade_id": "cell-abad6a4c25b1678f",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "class MLP(object):\n",
    "    ''' A Multi-Layer Perceptron.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, layers, weight_init_int=(-.7, .7), method='fullbatch',\n",
    "            max_iter=1000, learning_rate=0.3, dlr=0.1, alpha=0., epsilon=0.01,\n",
    "            minimethod='CG', batchsize=30):\n",
    "        '''\n",
    "        layers: tuple\n",
    "            The elements of the tuple define the number of units in all hidden\n",
    "            layers (bias units not included), i.e. a tuple (20, 30, 40) defines\n",
    "            a MLP with three hidden layers of 20, 30 and 40 hidden units plus\n",
    "            bias units.\n",
    "\n",
    "        weight_init_int: tuple =(-.7, .7)\n",
    "            The interval on which the weights/thetas will be randomly initialized.\n",
    "\n",
    "        alpha: float\n",
    "            The l2 regularization strength.\n",
    "\n",
    "        method: string\n",
    "            'fullbatch', 'minibatch', 'sgd', 'minimize'\n",
    "\n",
    "        epsilon: float\n",
    "            The threshold value for the length of the gradient for stopping gradient\n",
    "            descent iterations.\n",
    "            \n",
    "        learning_rate: float\n",
    "            The (initial) step size.\n",
    "            \n",
    "        max_iter: int\n",
    "            The maximal number of gradient descent iterations.\n",
    "            \n",
    "        dlr: float\n",
    "            The adaptive learning rate constant d.\n",
    "            \n",
    "        batchsize: int\n",
    "            The number of samples in batch when using the minibatch method for optimizing.\n",
    "            \n",
    "        minimethod: string\n",
    "            The algorithm used by the minimize library function for optimizing the\n",
    "            model coefficients / thetas / weights. (use 'CG' or 'L-BFGS-B')\n",
    "        '''\n",
    "        # the model\n",
    "        self.layers = layers\n",
    "        self.weight_init_int = weight_init_int\n",
    "        self.alpha = alpha\n",
    "        # basic gradient decscent params\n",
    "        self.method = method\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        # batched gradient descent\n",
    "        self.dlr = dlr\n",
    "        self.batchsize = batchsize\n",
    "        # when using scipy.optimize.minimize\n",
    "        self.minimethod = minimethod\n",
    "\n",
    "        print('MLP(layers={}, weight_init={}, method=\"{}\", alpha={}, learning_rate={}, dlr={})'.format(\n",
    "            self.layers, self.weight_init_int, self.method, self.alpha, self.learning_rate, self.dlr))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Configures input and output layer, initializes weights and fits the\n",
    "        model coefficients.\n",
    "        '''\n",
    "        # initialize the entire network, including input and ouput layer\n",
    "        y_ = self._init_network(X, y)\n",
    "\n",
    "        if self.method == 'fullbatch':\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        elif self.method == 'sgd':\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        elif self.method == 'minibatch':\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        elif self.method == 'minimize':\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def cost_function(theta_, alpha, X, y, theta_shapes=None):\n",
    "        '''Computes the cross-entropy cost function.\n",
    "\n",
    "        Uses MLP.forward_propagation\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        theta_ : the weights of the neural network\n",
    "        alpha : the regularization strength\n",
    "        X, y : the data\n",
    "        theta_shapes : a list of tuples defining the shapes of theta\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        J : cost function value given thetas\n",
    "\n",
    "        '''\n",
    "        # Implementation Hint:\n",
    "        # Use np.nan_to_num to ensure numpy handles values very close to zero\n",
    "        # correctly in the log function\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @staticmethod\n",
    "    def gradient_cost_function(theta_, alpha, X, y, theta_shapes=None):\n",
    "        '''Computes the gradient of the cost function.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        theta_ : the weights of the neural network\n",
    "        theta_shapes : a list of tuples defining the shapes of theta\n",
    "        alpha : the regularization strength\n",
    "        X, y : the data\n",
    "\n",
    "        If theta_shapes is provided (i.e. not None) the thetas are received as\n",
    "        a 1-d array and rolled-up first. The gradient is then computed. After\n",
    "        that, if rolled-up initially, the gradient is unrolled again, e.g. for\n",
    "        further use in an optimizer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        grad : the gradient of the cost function\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward_propagation(theta, x):\n",
    "        '''Computes the activations for all units in an MLP given by theta for\n",
    "        a single data point x.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        a : activations of all units as a list of arrays\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @staticmethod\n",
    "    def back_propagation(theta, a, y):\n",
    "        '''Computes the error d for all units.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        d : the error (small delta) propagated back through the network as list\n",
    "        of arrays.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def grad_check(self, X, y, epsilon=0.0001, decimal=3, verbose=False):\n",
    "        '''Compare the gradient with finite differences around current point\n",
    "        in parameter space.\n",
    "        '''\n",
    "        if not 'theta' in dir(self):\n",
    "            _ = self._init_network(X, y)\n",
    "\n",
    "        theta_ur = MLP.unroll(self.theta)\n",
    "\n",
    "        # approximate the gradient with finite differences\n",
    "        approxgrad = []\n",
    "        for idx in range(len(theta_ur)):\n",
    "            # modify theta[idx] +/- epsilon\n",
    "            tplus = theta_ur.copy()\n",
    "            tplus[idx] = tplus[idx]+epsilon\n",
    "            tminus = theta_ur.copy()\n",
    "            tminus[idx] = tminus[idx]-epsilon\n",
    "            # calculate the costfunctions\n",
    "            minuseps = MLP.cost_function(tminus, self.alpha, X, y, self._theta_shapes)\n",
    "            pluseps = MLP.cost_function(tplus, self.alpha, X, y, self._theta_shapes)\n",
    "            # finite diffs\n",
    "            approxgrad.append((pluseps - minuseps)/(2*epsilon))\n",
    "\n",
    "        approxgrad = np.array(approxgrad)\n",
    "\n",
    "        # compare normalized gradients\n",
    "        approxgrad /= np.linalg.norm(approxgrad)\n",
    "        calcgrad = MLP.gradient_cost_function(theta_ur, self.alpha, X, y, self._theta_shapes)\n",
    "        # compare normalized gradients\n",
    "        calcgrad /= np.linalg.norm(calcgrad)\n",
    "\n",
    "        if verbose:\n",
    "            print('approx : ', approxgrad)\n",
    "            print('backprop : ', calcgrad)\n",
    "\n",
    "        np.testing.assert_array_almost_equal(approxgrad, calcgrad, decimal=decimal)\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''Predicts the output for all data points in X.\n",
    "\n",
    "        Makes use of MLP.forward_propagation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prediction of output\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def score(self, X, y):\n",
    "        '''Computes the accuracy metric for the predictions on X, given the\n",
    "        true output y.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        accuracy : metric computed for X and y, invoking a prediction on X,\n",
    "        given the current model\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @staticmethod\n",
    "    def rollup_if(x_, shapes):\n",
    "        '''Conditional uprolling if shapes is not None.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x : list of arrays, if shapes provided, input x_ otherwise\n",
    "        True/False : True if input has been rolled up.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @staticmethod\n",
    "    def unroll(xlist):\n",
    "        '''Unrolling theta in a 1d array (that can be passed into minimize).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x : unrolled 1-d array\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @staticmethod\n",
    "    def rollup(xur, shapes):\n",
    "        '''Rolling up theta into a list of 2d matrices.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        xlist : list of 2-d arrays extracted from xur, reshaped into shapes.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @staticmethod\n",
    "    def phi(t):\n",
    "        '''Logistic / sigmoid function.'''\n",
    "        return 1. / (1 + np.exp(-t))\n",
    "\n",
    "    def _init_network(self, X, y):\n",
    "        '''Initializes all that's necessary to start training.\n",
    "\n",
    "        - transforms y as required to one-hot-encoding and returns encoded y_\n",
    "        - completes self.layers\n",
    "        - initializes thetas, using MLP.theta_init, as list of 2-d matrices\n",
    "        - sets self._theta_shapes (needed for unrolling and uprolling)\n",
    "\n",
    "        (uses init_theta())\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_ : one-hot encoded categories contained in y.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @staticmethod\n",
    "    def init_theta(layers, weight_init_int):\n",
    "        '''Initializes the thetas and returns them as a list of 2-d matrices.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        theta : list of model coefficients 2-arrays according to the layer\n",
    "        specification.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    # ADD ADDITIONAL UTILITY METHODS HERE\n",
    "    # YOU CAN REMOVE THE NotImplementedError right\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d227b7dd311c9fba99a33dc915e619a",
     "grade": true,
     "grade_id": "cell-203de191c19809d0",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Demo\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d70535e213456dc5a11638838957eb94",
     "grade": true,
     "grade_id": "cell-fe3003ab0afdc39d",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b4db68fc4f6ddc6e72c5018a25b6941",
     "grade": false,
     "grade_id": "cell-7ea909e0f0a9e787",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 5 - MLP Anwendung (5 Punkte)\n",
    "\n",
    "Verwende deine Implementierung des Multi-Layer Perceptrons, um unseren Datensatz zu klassifizieren.  \n",
    "(Falls deine Implementierung nicht funktionieren sollte, kann du scikit-learn verwenden. Damit kannst du noch 3 Punkte erreichen.)\n",
    "\n",
    "Finde ein möglichst gutes Modell im Sinne der Zielmetrik.  \n",
    "\n",
    "Evaluiere und diskutiere die Resultate, zeichne dabei auch die Confusion Matrix auf dem Testset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa2a1288e1cadaa6024577700cbad86b",
     "grade": true,
     "grade_id": "cell-6f177b0a63888e57",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8bde5214489d18af22a39cc8d9073680",
     "grade": true,
     "grade_id": "cell-bfa1203293021b51",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4271e58003d17dc4c40c1df032514c1",
     "grade": false,
     "grade_id": "cell-bda67a99b7d462b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 6 - Decision Tree - Theorie (6 Punkte)\n",
    "\n",
    "Erkläre wie ein Decision Tree erstellt wird.  \n",
    "\n",
    "Welche Rolle spielen dabei Metriken wie die Entropie oder Gini-Index?  \n",
    "\n",
    "Was sind die Eigenschaften der Decision Boundary bei Decision Trees?  \n",
    "\n",
    "Wodurch kann bei Decision Trees Overfitting entstehen? Diskutiere welche Ansätze möglich sind, um Overfitting zu vermeiden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a922f6cf1ac2d9eff8926e8b33b6754c",
     "grade": true,
     "grade_id": "cell-c3bbc0b21a0068d0",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3a347ee60aad9c469b69083479dec83",
     "grade": false,
     "grade_id": "cell-79c33822601c79cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 7 - Decision Tree - Anwendung I (4 Punkte)\n",
    "\n",
    "Betrachte nun eine Vorhersage der Variablen `has_mfk`.  \n",
    "Berechne dazu einen Entscheidungsbaum mit vier Teilräumen 'manuell', das heisst, bloss auf der Basis von Numpy-Funktionalität und unter Verwendung des Gini-Index.  \n",
    "\n",
    "Visualisiere den resultierenden Baum und diskutiere seine Entstehung.  \n",
    "\n",
    "Wie gut ist die Vorhersage? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e423a76a28e0ccf5e68b2b51924f768b",
     "grade": true,
     "grade_id": "cell-7d7df66ef55a59ad",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef7b5428f086aef0d624647b2920a5e2",
     "grade": true,
     "grade_id": "cell-47d8589145b68c61",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "559de5d4fd621bdd02c26eef0b13992a",
     "grade": false,
     "grade_id": "cell-6f69af94b90bca4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 8 - Decision Tree - Anwendung II (5 Punkte)\n",
    "\n",
    "Verwende nun einen Decision Tree von scikit-learn zur Klassifikation von `brand`.\n",
    "\n",
    "Zeichne den besten resultierenden Baum und erkläre ihn.\n",
    "\n",
    "Evaluiere und diskutiere die Resultate, zeichne dabei auch die Confusion Matrix auf dem Testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59f748a0fc9215121b9a8b0d313d10d8",
     "grade": true,
     "grade_id": "cell-d941df1b92fe60db",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fb9ac5471d973e7fdcc3357a7acb5f0",
     "grade": true,
     "grade_id": "cell-e1cbda8282c23050",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1a323a96461cad15dce9d7491d1c473",
     "grade": false,
     "grade_id": "cell-e531247d7b2c0f05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 9 - Bestes Modell (4 Punkte)\n",
    "\n",
    "Nun bist du frei eine beliebiges scikit-learn Modell zur Vorhersage von `brand` zu verwenden, um eine möglichst gute Vorhersage im Sinne unserer Zielmetrik zu erreichen.  \n",
    "\n",
    "Zeichne die Confusion Matrix auf dem Testset und diskutiere die Resultate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bfafa540908457b6e644cc020b27f1b",
     "grade": true,
     "grade_id": "cell-bc17e4c653824a49",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55931adde201306a57ed233c675d555c",
     "grade": true,
     "grade_id": "cell-f6fdd6a537646051",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "afc03fe3de4849c0d1a2baf64a2eafa0",
     "grade": false,
     "grade_id": "cell-0d16b45e56a492d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 10 - Übersicht der Resultate (3 Punkte)\n",
    "\n",
    "Stelle die Resultate der verschiedenen Modelle zur Vorhersage von `brand` in einer Tabelle zusammen und auch graphisch dar.  \n",
    "\n",
    "Diskutiere deine Einsichten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f3350a5cf0eff47de7b92c95dcb0889",
     "grade": true,
     "grade_id": "cell-9276cb37fd8d438d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b4fe635f8e4cb16448cfb52f516e5dc",
     "grade": true,
     "grade_id": "cell-eb2b63ef857c55db",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
